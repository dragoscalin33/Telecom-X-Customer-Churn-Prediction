# üìä Telecom X: Churn Prediction

## Project Overview
This Data Science project focuses on developing predictive models to identify customers at high risk of churning (leaving the service) at the telecommunications company "Telecom X". Customer retention is a critical strategic pillar for any business, and the ability to predict churn allows for proactive intervention, implementation of loyalty strategies, and minimization of financial losses.

In this repository, you will find a complete Machine Learning pipeline, from robust data preprocessing to model evaluation and the extraction of actionable business insights.

## üéØ Project Objectives
Data Preparation: Perform data cleaning, transformation, feature engineering, and variable encoding to prepare the dataset for ML models.

Exploratory Data Analysis (EDA): Understand data distribution and relationships between variables, with a special focus on the target variable (churn).

Class Balancing: Address the imbalance between churn classes (churned vs. retained customers) to prevent model bias.

Predictive Modeling: Train and compare multiple classification models to predict churn.

Model Evaluation: Utilize relevant performance metrics (Accuracy, Precision, Recall, F1-score, Confusion Matrix) to select the most effective model for the business problem.

Interpretability: Analyze feature importance to understand the main factors driving customer churn.

Strategic Conclusions: Provide data-driven recommendations for Telecom X, aiming to improve customer retention.

## üìÅ Repository Structure
TelecomX_Data.json: Raw dataset from Telecom X (original source).

telecomX_datos.csv: Preprocessed and cleaned dataset, ready for modeling (generated by Part 1 of the Colab).

TelecomX_Customer_Retention_Study: Notebook/script for Part 1, responsible for data loading, cleaning, and preprocessing, saving the result to telecomX_datos.csv.

Telecom-X-Customer-Churn-Prediction: Notebook/script for Part 2, which loads the processed data and executes the modeling, evaluation, and feature importance analysis steps.

## üöÄ Methodology
The project followed these key steps:

Data Loading and Preprocessing:

Raw data was loaded from a JSON file.

Nested columns were flattened to facilitate manipulation.

Columns were renamed for clarity and standardization.

Duplicate and missing values (especially in the total_charges column) were handled.

A new feature, daily_charges (average daily customer cost), was engineered.

The churn_original variable was binarized to churn_bin (0=Stayed, 1=Churned), along with other binary columns.

Categorical Variable Encoding:

pd.get_dummies was used to apply One-Hot Encoding to categorical variables (gender, internet_service, contract, payment_method). The drop_first=True parameter was employed to prevent multicollinearity, ensuring model stability and interpretability.

Class Balancing:

A significant imbalance was identified in the churn_bin variable (approximately 73% retained vs. 27% churned customers).

To mitigate model bias towards the majority class, the SMOTE (Synthetic Minority Over-sampling Technique) oversampling technique was applied, generating synthetic samples of the minority class.

Data Normalization/Standardization:

StandardScaler was applied to standardize numerical features. This step is crucial for scale-sensitive models (like Logistic Regression), ensuring all features contribute equally to model training and avoiding data leakage by being applied only to the training data.

Correlation Analysis:

A correlation matrix was generated to understand the linear relationships between predictor variables and the churn_bin variable. Bar plots were used to visualize the strongest correlations, and box plots to explore the relationship of key numerical variables with churn.

Model Training and Evaluation:

Data was split into stratified training (70%) and test (30%) sets to maintain class proportions.

Two classification models were trained:

Logistic Regression: An interpretable linear model, trained with scaled data.

Random Forest Classifier: A robust tree-based ensemble model, capable of capturing non-linearities and less sensitive to data scale (trained with unscaled data).

Models were evaluated using: Accuracy, Precision, Recall, F1-score, and Confusion Matrix.

## üìà Results and Key Insights
Following evaluation, the Random Forest Classifier demonstrated superior overall performance for this churn prediction problem, especially regarding Recall (the ability to correctly identify customers who will churn), a critical metric for proactive interventions.

Random Forest Metrics (Test Set):

Accuracy: 0.8428

Precision: 0.8298

Recall: 0.8625

F1-score: 0.8458

Logistic Regression Metrics (Test Set):

Accuracy: 0.8228

Precision: 0.8193

Recall: 0.8283

F1-score: 0.8238

The feature importance analysis revealed the following key factors influencing churn:

tenure (Contract Tenure): The most impactful variable. Customers with shorter contract tenure are significantly more likely to churn.

contract_Month-to-month (Month-to-month Contract): Customers on monthly contracts have a much higher probability of churn compared to one-year or two-year contracts.

payment_method_Electronic check (Electronic Check Payment Method): This payment method is strongly associated with a higher churn rate.

internet_service_Fiber optic (Fiber Optic Internet Service): Surprisingly, customers with fiber optic service also show a higher tendency to churn, suggesting potential service quality issues or unmet expectations.

monthly_charges (Monthly Charges): Higher monthly fees tend to increase the likelihood of churn.

Additional Services (online_security, tech_support, online_backup): The absence or non-subscription to these services correlates with higher churn, indicating that customers with more services tend to be more loyal.

## üí° Strategic Recommendations for Telecom X
Based on the insights gained from the predictive models, I suggest the following actions for Telecom X:

Focus on New Customers: Implement enhanced welcome programs and proactive follow-ups during the first few months of the contract (tenure), offering support and encouraging subscription to additional services.

Incentivize Long-Term Contracts: Create attractive offers and benefits to encourage customers to migrate from monthly plans to annual or biennial contracts, emphasizing stability and cost-effectiveness.

Optimize 'Electronic Check' Payment Method: Investigate the causes of dissatisfaction associated with "Electronic Check." It may be necessary to improve the user experience with this method or actively promote more convenient and secure alternatives.

Improve Fiber Optic Service Quality: Conduct an in-depth analysis of the fiber optic customer experience. Satisfaction surveys and service quality monitoring can reveal pain points and improvement opportunities.

Promote Value-Added Services: Highlight the value and security of additional services (online security, technical support, backup) to increase adoption and, consequently, customer loyalty.

Review Pricing Structure: Evaluate the competitiveness of plans with high monthly fees, considering offering more flexible packages or discounts for high-spending customers, ensuring that the perceived value justifies the cost.

## üõ†Ô∏è Technologies Used
Python

Pandas

NumPy

Seaborn

Matplotlib

Scikit-learn

Imbalanced-learn (imblearn)
